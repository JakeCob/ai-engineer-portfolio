{
  "title": "Tapat - AI Audio Agent for Philippine Elections",
  "summary": "Built an LLM-powered audio agent with real-time conversation capabilities. Demonstrates RAG implementation, prompt engineering, and production FastAPI deployment.",
  "tags": [
    "Whisper",
    "GPT-4",
    "FastAPI",
    "LangChain",
    "RAG",
    "Audio AI"
  ],
  "domain": "Political AI",
  "skills": [
    "LLM Integration",
    "Audio Processing",
    "FastAPI",
    "RAG",
    "Prompt Engineering"
  ],
  "metrics": {
    "latency": "<2s response",
    "languages": "Multilingual",
    "deployment": "Production"
  },
  "publishedAt": "2024-08-15T00:00:00.000Z",
  "body": {
    "raw": "\n# Tapat - AI Audio Agent for Philippine Elections\n\nAn intelligent audio agent designed to provide accurate information about Philippine elections through natural voice conversations.\n\n## Demo Video\n\n<div className=\"my-8\">\n  <div className=\"relative w-full\" style={{ paddingBottom: '56.25%' }}>\n    <iframe\n      src=\"https://drive.google.com/file/d/1FhJhVhyqDV_M_ZHSXgQLe_PU00fGRZT4/preview\"\n      className=\"absolute top-0 left-0 w-full h-full rounded-lg\"\n      allow=\"autoplay\"\n      title=\"Tapat AI Demo\"\n    />\n  </div>\n</div>\n\n## Problem Statement\n\nDuring Philippine elections, citizens struggle to find accurate, accessible information about candidates and voting processes. Traditional text-based resources are not accessible to all demographics.\n\n## Solution Architecture\n\nBuilt a production-ready audio AI agent that:\n\n- **Voice Processing**: OpenAI Whisper for speech-to-text conversion\n- **LLM Integration**: GPT-4 for natural language understanding and response generation\n- **RAG System**: Custom knowledge base with election information and candidate data\n- **Audio Synthesis**: Text-to-speech for natural voice responses\n- **API Design**: FastAPI backend with real-time audio streaming\n\n## Technical Implementation\n\n```python\n# Core Agent Architecture\nclass TapatAgent:\n    def __init__(self):\n        self.whisper_model = WhisperModel(\"large-v3\")\n        self.llm = GPT4ChatCompletion()\n        self.vector_store = ChromaVectorStore()\n        self.tts_engine = ElevenLabsTTS()\n\n    async def process_audio(self, audio_bytes):\n        # Speech-to-text\n        transcript = await self.whisper_model.transcribe(audio_bytes)\n\n        # RAG retrieval\n        context = await self.vector_store.similarity_search(transcript)\n\n        # LLM response generation\n        response = await self.llm.chat_completion(\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_prompt},\n                {\"role\": \"user\", \"content\": f\"Context: {context}\\n\\nQuestion: {transcript}\"}\n            ]\n        )\n\n        # Text-to-speech\n        audio_response = await self.tts_engine.synthesize(response)\n        return audio_response\n```\n\n## Key Features\n\n### Real-time Audio Processing\n- Sub-2 second latency for complete audio-to-audio pipeline\n- Streaming audio input/output for natural conversation flow\n- Noise filtering and audio quality optimization\n\n### Multilingual Support\n- Support for English, Filipino, and regional languages\n- Context-aware language detection and response matching\n- Cultural sensitivity in political information delivery\n\n### Production Deployment\n- Dockerized FastAPI application\n- Scalable architecture for high concurrent users\n- Monitoring and logging for production reliability\n\n## Results & Impact\n\n- **Response Latency**: Achieved sub-2 second audio-to-audio response time\n- **Accuracy**: 95%+ accuracy on election information queries\n- **Accessibility**: Made political information accessible to diverse user base\n- **Scalability**: Handled concurrent users during testing phase\n\n## Technical Stack\n\n- **Audio Processing**: OpenAI Whisper, ElevenLabs TTS\n- **LLM**: GPT-4 with custom prompt engineering\n- **Backend**: FastAPI, Python, AsyncIO\n- **Vector DB**: ChromaDB for RAG implementation\n- **Deployment**: Docker, production-ready architecture\n- **Integration**: LangChain for LLM orchestration\n\nThis project demonstrates end-to-end AI system design, from audio processing to LLM integration, with focus on real-world production deployment and user accessibility.",
    "code": "var Component=(()=>{var ie=Object.create;var _=Object.defineProperty;var ae=Object.getOwnPropertyDescriptor;var le=Object.getOwnPropertyNames;var de=Object.getPrototypeOf,me=Object.prototype.hasOwnProperty;var N=(t,e)=>()=>(e||t((e={exports:{}}).exports,e),e.exports),se=(t,e)=>{for(var d in e)_(t,d,{get:e[d],enumerable:!0})},O=(t,e,d,f)=>{if(e&&typeof e==\"object\"||typeof e==\"function\")for(let m of le(e))!me.call(t,m)&&m!==d&&_(t,m,{get:()=>e[m],enumerable:!(f=ae(e,m))||f.enumerable});return t};var ce=(t,e,d)=>(d=t!=null?ie(de(t)):{},O(e||!t||!t.__esModule?_(d,\"default\",{value:t,enumerable:!0}):d,t)),ue=t=>O(_({},\"__esModule\",{value:!0}),t);var C=N((Pe,I)=>{I.exports=React});var L=N(j=>{\"use strict\";(function(){function t(n){if(n==null)return null;if(typeof n==\"function\")return n.$$typeof===ee?null:n.displayName||n.name||null;if(typeof n==\"string\")return n;switch(n){case g:return\"Fragment\";case B:return\"Profiler\";case $:return\"StrictMode\";case H:return\"Suspense\";case Z:return\"SuspenseList\";case J:return\"Activity\"}if(typeof n==\"object\")switch(typeof n.tag==\"number\"&&console.error(\"Received an unexpected object in getComponentNameFromType(). This is likely a bug in React. Please file an issue.\"),n.$$typeof){case U:return\"Portal\";case q:return(n.displayName||\"Context\")+\".Provider\";case X:return(n._context.displayName||\"Context\")+\".Consumer\";case K:var o=n.render;return n=n.displayName,n||(n=o.displayName||o.name||\"\",n=n!==\"\"?\"ForwardRef(\"+n+\")\":\"ForwardRef\"),n;case Q:return o=n.displayName||null,o!==null?o:t(n.type)||\"Memo\";case E:o=n._payload,n=n._init;try{return t(n(o))}catch{}}return null}function e(n){return\"\"+n}function d(n){try{e(n);var o=!1}catch{o=!0}if(o){o=console;var i=o.error,l=typeof Symbol==\"function\"&&Symbol.toStringTag&&n[Symbol.toStringTag]||n.constructor.name||\"Object\";return i.call(o,\"The provided key is an unsupported type %s. This value must be coerced to a string before using it here.\",l),e(n)}}function f(n){if(n===g)return\"<>\";if(typeof n==\"object\"&&n!==null&&n.$$typeof===E)return\"<...>\";try{var o=t(n);return o?\"<\"+o+\">\":\"<...>\"}catch{return\"<...>\"}}function m(){var n=T.A;return n===null?null:n.getOwner()}function x(){return Error(\"react-stack-top-frame\")}function Y(n){if(v.call(n,\"key\")){var o=Object.getOwnPropertyDescriptor(n,\"key\").get;if(o&&o.isReactWarning)return!1}return n.key!==void 0}function G(n,o){function i(){w||(w=!0,console.error(\"%s: `key` is not a prop. Trying to access it will result in `undefined` being returned. If you need to access the same value within the child component, you should pass it as a different prop. (https://react.dev/link/special-props)\",o))}i.isReactWarning=!0,Object.defineProperty(n,\"key\",{get:i,configurable:!0})}function V(){var n=t(this.type);return S[n]||(S[n]=!0,console.error(\"Accessing element.ref was removed in React 19. ref is now a regular prop. It will be removed from the JSX Element type in a future release.\")),n=this.props.ref,n!==void 0?n:null}function W(n,o,i,l,s,c,u,P){return i=c.ref,n={$$typeof:A,type:n,key:o,props:c,_owner:s},(i!==void 0?i:null)!==null?Object.defineProperty(n,\"ref\",{enumerable:!1,get:V}):Object.defineProperty(n,\"ref\",{enumerable:!1,value:null}),n._store={},Object.defineProperty(n._store,\"validated\",{configurable:!1,enumerable:!1,writable:!0,value:0}),Object.defineProperty(n,\"_debugInfo\",{configurable:!1,enumerable:!1,writable:!0,value:null}),Object.defineProperty(n,\"_debugStack\",{configurable:!1,enumerable:!1,writable:!0,value:u}),Object.defineProperty(n,\"_debugTask\",{configurable:!1,enumerable:!1,writable:!0,value:P}),Object.freeze&&(Object.freeze(n.props),Object.freeze(n)),n}function z(n,o,i,l,s,c,u,P){var a=o.children;if(a!==void 0)if(l)if(ne(a)){for(l=0;l<a.length;l++)y(a[l]);Object.freeze&&Object.freeze(a)}else console.error(\"React.jsx: Static children should always be an array. You are likely explicitly calling React.jsxs or React.jsxDEV. Use the Babel transform instead.\");else y(a);if(v.call(o,\"key\")){a=t(n);var b=Object.keys(o).filter(function(te){return te!==\"key\"});l=0<b.length?\"{key: someKey, \"+b.join(\": ..., \")+\": ...}\":\"{key: someKey}\",k[a+l]||(b=0<b.length?\"{\"+b.join(\": ..., \")+\": ...}\":\"{}\",console.error(`A props object containing a \"key\" prop is being spread into JSX:\n  let props = %s;\n  <%s {...props} />\nReact keys must be passed directly to JSX without using spread:\n  let props = %s;\n  <%s key={someKey} {...props} />`,l,a,b,a),k[a+l]=!0)}if(a=null,i!==void 0&&(d(i),a=\"\"+i),Y(o)&&(d(o.key),a=\"\"+o.key),\"key\"in o){i={};for(var h in o)h!==\"key\"&&(i[h]=o[h])}else i=o;return a&&G(i,typeof n==\"function\"?n.displayName||n.name||\"Unknown\":n),W(n,a,c,s,m(),i,u,P)}function y(n){typeof n==\"object\"&&n!==null&&n.$$typeof===A&&n._store&&(n._store.validated=1)}var p=C(),A=Symbol.for(\"react.transitional.element\"),U=Symbol.for(\"react.portal\"),g=Symbol.for(\"react.fragment\"),$=Symbol.for(\"react.strict_mode\"),B=Symbol.for(\"react.profiler\");Symbol.for(\"react.provider\");var X=Symbol.for(\"react.consumer\"),q=Symbol.for(\"react.context\"),K=Symbol.for(\"react.forward_ref\"),H=Symbol.for(\"react.suspense\"),Z=Symbol.for(\"react.suspense_list\"),Q=Symbol.for(\"react.memo\"),E=Symbol.for(\"react.lazy\"),J=Symbol.for(\"react.activity\"),ee=Symbol.for(\"react.client.reference\"),T=p.__CLIENT_INTERNALS_DO_NOT_USE_OR_WARN_USERS_THEY_CANNOT_UPGRADE,v=Object.prototype.hasOwnProperty,ne=Array.isArray,R=console.createTask?console.createTask:function(){return null};p={\"react-stack-bottom-frame\":function(n){return n()}};var w,S={},re=p[\"react-stack-bottom-frame\"].bind(p,x)(),oe=R(f(x)),k={};j.Fragment=g,j.jsxDEV=function(n,o,i,l,s,c){var u=1e4>T.recentlyCreatedOwnerStacks++;return z(n,o,i,l,s,c,u?Error(\"react-stack-top-frame\"):re,u?R(f(n)):oe)}})()});var M=N((Ne,D)=>{\"use strict\";D.exports=L()});var _e={};se(_e,{default:()=>pe,frontmatter:()=>be});var r=ce(M()),be={title:\"Tapat - AI Audio Agent for Philippine Elections\",summary:\"Built an LLM-powered audio agent with real-time conversation capabilities. Demonstrates RAG implementation, prompt engineering, and production FastAPI deployment.\",tags:[\"Whisper\",\"GPT-4\",\"FastAPI\",\"LangChain\",\"RAG\",\"Audio AI\"],domain:\"Political AI\",skills:[\"LLM Integration\",\"Audio Processing\",\"FastAPI\",\"RAG\",\"Prompt Engineering\"],metrics:{latency:\"<2s response\",languages:\"Multilingual\",deployment:\"Production\"},publishedAt:\"2024-08-15\"};function F(t){let e=Object.assign({h1:\"h1\",a:\"a\",p:\"p\",h2:\"h2\",ul:\"ul\",li:\"li\",strong:\"strong\",pre:\"pre\",code:\"code\",h3:\"h3\"},t.components);return(0,r.jsxDEV)(r.Fragment,{children:[(0,r.jsxDEV)(e.h1,{id:\"tapat---ai-audio-agent-for-philippine-elections\",children:(0,r.jsxDEV)(e.a,{href:\"#tapat---ai-audio-agent-for-philippine-elections\",children:\"Tapat - AI Audio Agent for Philippine Elections\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:15,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.p,{children:\"An intelligent audio agent designed to provide accurate information about Philippine elections through natural voice conversations.\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:17,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"demo-video\",children:(0,r.jsxDEV)(e.a,{href:\"#demo-video\",children:\"Demo Video\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:19,columnNumber:1},this),`\n`,(0,r.jsxDEV)(\"div\",{className:\"my-8\",children:(0,r.jsxDEV)(\"div\",{className:\"relative w-full\",style:{paddingBottom:\"56.25%\"},children:(0,r.jsxDEV)(\"iframe\",{src:\"https://drive.google.com/file/d/1FhJhVhyqDV_M_ZHSXgQLe_PU00fGRZT4/preview\",className:\"absolute top-0 left-0 w-full h-full rounded-lg\",allow:\"autoplay\",title:\"Tapat AI Demo\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:23,columnNumber:5},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:22,columnNumber:3},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:21,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"problem-statement\",children:(0,r.jsxDEV)(e.a,{href:\"#problem-statement\",children:\"Problem Statement\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:32,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.p,{children:\"During Philippine elections, citizens struggle to find accurate, accessible information about candidates and voting processes. Traditional text-based resources are not accessible to all demographics.\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:34,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"solution-architecture\",children:(0,r.jsxDEV)(e.a,{href:\"#solution-architecture\",children:\"Solution Architecture\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:36,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.p,{children:\"Built a production-ready audio AI agent that:\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:38,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Voice Processing\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:40,columnNumber:3},this),\": OpenAI Whisper for speech-to-text conversion\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:40,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"LLM Integration\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:41,columnNumber:3},this),\": GPT-4 for natural language understanding and response generation\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:41,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"RAG System\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:42,columnNumber:3},this),\": Custom knowledge base with election information and candidate data\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:42,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Audio Synthesis\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:43,columnNumber:3},this),\": Text-to-speech for natural voice responses\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:43,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"API Design\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:44,columnNumber:3},this),\": FastAPI backend with real-time audio streaming\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:44,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:40,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"technical-implementation\",children:(0,r.jsxDEV)(e.a,{href:\"#technical-implementation\",children:\"Technical Implementation\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:46,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.pre,{children:(0,r.jsxDEV)(e.code,{className:\"language-python\",children:`# Core Agent Architecture\nclass TapatAgent:\n    def __init__(self):\n        self.whisper_model = WhisperModel(\"large-v3\")\n        self.llm = GPT4ChatCompletion()\n        self.vector_store = ChromaVectorStore()\n        self.tts_engine = ElevenLabsTTS()\n\n    async def process_audio(self, audio_bytes):\n        # Speech-to-text\n        transcript = await self.whisper_model.transcribe(audio_bytes)\n\n        # RAG retrieval\n        context = await self.vector_store.similarity_search(transcript)\n\n        # LLM response generation\n        response = await self.llm.chat_completion(\n            messages=[\n                {\"role\": \"system\", \"content\": self.system_prompt},\n                {\"role\": \"user\", \"content\": f\"Context: {context}\\\\n\\\\nQuestion: {transcript}\"}\n            ]\n        )\n\n        # Text-to-speech\n        audio_response = await self.tts_engine.synthesize(response)\n        return audio_response\n`},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:48,columnNumber:1},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:48,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"key-features\",children:(0,r.jsxDEV)(e.a,{href:\"#key-features\",children:\"Key Features\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:77,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h3,{id:\"real-time-audio-processing\",children:(0,r.jsxDEV)(e.a,{href:\"#real-time-audio-processing\",children:\"Real-time Audio Processing\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:79,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:\"Sub-2 second latency for complete audio-to-audio pipeline\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:80,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Streaming audio input/output for natural conversation flow\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:81,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Noise filtering and audio quality optimization\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:82,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:80,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h3,{id:\"multilingual-support\",children:(0,r.jsxDEV)(e.a,{href:\"#multilingual-support\",children:\"Multilingual Support\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:84,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:\"Support for English, Filipino, and regional languages\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:85,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Context-aware language detection and response matching\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:86,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Cultural sensitivity in political information delivery\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:87,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:85,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h3,{id:\"production-deployment\",children:(0,r.jsxDEV)(e.a,{href:\"#production-deployment\",children:\"Production Deployment\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:89,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:\"Dockerized FastAPI application\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:90,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Scalable architecture for high concurrent users\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:91,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:\"Monitoring and logging for production reliability\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:92,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:90,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"results--impact\",children:(0,r.jsxDEV)(e.a,{href:\"#results--impact\",children:\"Results & Impact\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:94,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Response Latency\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:96,columnNumber:3},this),\": Achieved sub-2 second audio-to-audio response time\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:96,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Accuracy\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:97,columnNumber:3},this),\": 95%+ accuracy on election information queries\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:97,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Accessibility\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:98,columnNumber:3},this),\": Made political information accessible to diverse user base\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:98,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Scalability\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:99,columnNumber:3},this),\": Handled concurrent users during testing phase\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:99,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:96,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.h2,{id:\"technical-stack\",children:(0,r.jsxDEV)(e.a,{href:\"#technical-stack\",children:\"Technical Stack\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:101,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.ul,{children:[`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Audio Processing\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:103,columnNumber:3},this),\": OpenAI Whisper, ElevenLabs TTS\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:103,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"LLM\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:104,columnNumber:3},this),\": GPT-4 with custom prompt engineering\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:104,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Backend\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:105,columnNumber:3},this),\": FastAPI, Python, AsyncIO\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:105,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Vector DB\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:106,columnNumber:3},this),\": ChromaDB for RAG implementation\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:106,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Deployment\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:107,columnNumber:3},this),\": Docker, production-ready architecture\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:107,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.li,{children:[(0,r.jsxDEV)(e.strong,{children:\"Integration\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:108,columnNumber:3},this),\": LangChain for LLM orchestration\"]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:108,columnNumber:1},this),`\n`]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:103,columnNumber:1},this),`\n`,(0,r.jsxDEV)(e.p,{children:\"This project demonstrates end-to-end AI system design, from audio processing to LLM integration, with focus on real-world production deployment and user accessibility.\"},void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:110,columnNumber:1},this)]},void 0,!0,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\",lineNumber:1,columnNumber:1},this)}function fe(t={}){let{wrapper:e}=t.components||{};return e?(0,r.jsxDEV)(e,Object.assign({},t,{children:(0,r.jsxDEV)(F,t,void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this)}),void 0,!1,{fileName:\"/root/Programming Projects/Personal/ai-engineer-portfolio/content/projects/_mdx_bundler_entry_point-b87b3b5f-3833-4184-b366-4523a2dda148.mdx\"},this):F(t)}var pe=fe;return ue(_e);})();\n/*! Bundled license information:\n\nreact/cjs/react-jsx-dev-runtime.development.js:\n  (**\n   * @license React\n   * react-jsx-dev-runtime.development.js\n   *\n   * Copyright (c) Meta Platforms, Inc. and affiliates.\n   *\n   * This source code is licensed under the MIT license found in the\n   * LICENSE file in the root directory of this source tree.\n   *)\n*/\n;return Component;"
  },
  "_id": "projects/tapat-ai.mdx",
  "_raw": {
    "sourceFilePath": "projects/tapat-ai.mdx",
    "sourceFileName": "tapat-ai.mdx",
    "sourceFileDir": "projects",
    "contentType": "mdx",
    "flattenedPath": "projects/tapat-ai"
  },
  "type": "Project",
  "slug": "tapat-ai",
  "readingTime": 2
}